# Basic Curriculum

![](https://user-images.githubusercontent.com/62965911/215325722-1f79be37-9ec0-4fd1-ab0f-b424b0365853.svg)

##### Table of Contents

- [Development Foundations](#development-foundations)
- [Data Engineering Foundations](#data-engineering-foundations)
- [Cloud Computing and Data Engineering tools in AWS](#cloud-computing-and-data-engineering-tools-in-aws)
- [Advanced Python Programming](#advanced-python-programming)
- [SQL Programming](#sql-programming)
- [Advanced PySpark Programming](#advanced-pyspark-programming)
- [Scala Programming](#scala-programming)
- [Data Modeling with RDBMS/NoSQL](#data-modeling-with-rdbms-nosql)
- [Data Warehouse and Data Lakes](#data-warehouse-and-data-lakes)
- [Big Data Processing](#big-data-processing)
- [Building Data Pipelines](#building-data-pipelines)
- [End-to-End Industry Grade Project](#end-to-end-industry-grade-project)

##### Estimated Time:

- Monologue mode: 20 hrs
- Interactive mode: 35 hours

## Development Foundations

### Tools and Concepts

1. Visual Studio Code (VSCode)
2. Anaconda
3. Github
4. Bash Shell

### Labs

* [ ] Download and Install vscode
* [ ] Understand vscode features
* [ ] Install extensions in vscode

  * [ ] Python Extensions Pack
  * [ ] Office Viewer
* [ ] Download and Install Anaconda
* [ ] Create virtual environment in anaconda
* [ ] Create test jupyter notebook in vscode and connect to venv
* [ ] Create github account
* [ ] Install git cli
* [ ] Create git repo and add student(s) as collaborator
* [ ] Connect local workspace to git repo
* [ ] Learn git commands

  * git init
  * git remote
  * git pull
  * git push
  * git add
  * git commit
  * git branch
  * git checkout
* [ ] Learn bash commands

## Data Engineering Foundations

### Tools and Concepts

1. What is Data Engineering?
2. Role of Data Engineering in Organizations
3. Skills required to become a Data Engineer
4. What is data lake and data warehouse?
5. What is medallion architecture?
6. What is EL, ETL and ELT?
7. What are the benefits of cloud computing?

## Cloud Computing and Data Engineering tools in AWS

### Tools and Concepts

1. AWS S3
2. RDS
3. Redshift
4. AWS Glue
5. Athena
6. AWS Lambda
7. EMR and EMR Serverless
8. Keyspace
9. Cloudformation
10. IAM
11. DBeaver

### Labs

1. [ ] (Optional) Create AWS Account
2. [ ] Create IAM user and generate credentials
3. [ ] Install AWS CLI
4. [ ] Setup AWS credentials
5. [ ] Walkthrough AWS Services
6. [ ] Copy and Sync data to/from S3
7. [ ] Create database in RDS DBMS and generate credentials
8. [ ] Install DBeaver in your PC
9. [ ] Connect to RDS DBMS from DBeaver

## Python Programming

### Tools and Concepts

1. Lists and dictionaries
2. For loops and while loops
3. Functions and Inline functions
4. Pandas Dataframes
5. `requests` library
6. `psycopg2` and `sqlalchemy` library

### Labs

1. Building Functions and Classes in Python
2. Read/Write and Manipulate Data using Pandas
3. Data Format Conversion - CSV to Parquet, JSON to CSV/Parquet
4. Pulling Data from APIs using requests library
5. Connect to Postgres and Redshift from Python
6. Load and Read the data from Postgres and Redshift using Python

## SQL Programming

### Labs

1. Hospital Data Analysis with SQL
2. Ecommerce Data Analysis with SQL
3. Order Analysis with Redshift SQL

## Advanced PySpark Programming

### Tools and Concepts

1. Spark and Hadoop Fundamentals
2. Databricks
3. Spark UDFs
4. Spark Dataframe API

### Labs

1. Create Databricks Account
2. Create Spark Cluster in Databricks
3. Data Transformation with PySpark
4. Connect AWS to PySpark
5. ETL Pipeline with AWS S3 and PySpark

## Scala Programming

### Labs

1. Introduction to Scala Programming
2. Transform complex data types

## Data Modeling with RDBMS/NoSQL

### Tools and Concepts

1. Data Modeling
2. SQL vs NoSQL
3. Star and Snowflake Schema
4. Postgres
5. Cassandra

### Labs

1. Music Data Modeling with Postgres
2. Music Data Modeling with Cassandra
3. Healthcare Data Modeling with Postgres

## Data Warehouse and Data Lakes

### Tools and Concepts

1. Data Warehouses vs Data Lakes
2. Data Lakes and Lakehouses

### Labs

1. Loading Data into Redshift
2. Queries in Redshift
3. Data lake with AWS, S3 and Athena
4. Working with Delta lake in Databricks

## Big Data Processing

### Tools and Concepts

1. Spark Jobs
2. EMR and EMR Serverless
3. Databricks
4. dbt

### Labs

1. Processing data with EMR Serverless
2. Processing data using dbt in Redshift
3. Processing data with Databricks

## Building Data Pipelines

### Tools and Concepts

1. Data Pipelines (ETL/ELT)
2. Apache Airflow
   1. UI
   2. Operators
   3. Variables
   4. Plugins
   5. Schedules
   6. etc.

### Labs

1. Install Airflow in your PC
2. Install Airflow in cloud
3. Building an ETL Data Pipeline with python and aws data lake
4. Building an ETL Data Pipeline with lambda and aws data lake
5. Building an ELT Data Pipeline with dbt, airflow and redshift

## End-to-End Industry Grade Project

- We will build an end-to-end project with tools and concepts we learned and adopted in the trainin sessions.
- The project will be added in your resume.
- We will also release the project in your github. (Recruiters are interested in seeing your projects in git)
